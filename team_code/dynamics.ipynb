{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d265ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy, argparse, pdb, os, time, math, random\n",
    "import utils\n",
    "from dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import importlib\n",
    "import models\n",
    "import torch.nn as nn\n",
    "\n",
    "import gym\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffcfbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--tensorboard_dir'], dest='tensorboard_dir', nargs=None, const=None, default='models', type=<class 'str'>, choices=None, help='path to the directory where to save tensorboard log. If passed empty path no logs are saved.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=1)\n",
    "parser.add_argument('--v', type=int, default=4)\n",
    "parser.add_argument('--dataset', type=str, default='i80')\n",
    "parser.add_argument('--model', type=str, default='fwd-cnn')\n",
    "parser.add_argument('--layers', type=int, default=3, help='layers in frame encoder/decoders')\n",
    "parser.add_argument('--data_dir', type=str, default='traffic-data/state-action-cost/data_i80_v0/')\n",
    "parser.add_argument('--model_dir', type=str, default='models')\n",
    "parser.add_argument('--ncond', type=int, default=20, help='number of conditioning frames')\n",
    "parser.add_argument('--npred', type=int, default=20, help='number of predictions to make with unrolled fwd model')\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--nfeature', type=int, default=256)\n",
    "parser.add_argument('--beta', type=float, default=0.0, help='coefficient for KL term in VAE')\n",
    "parser.add_argument('--ploss', type=str, default='hinge')\n",
    "parser.add_argument('--z_dropout', type=float, default=0.0, help='set z=0 with this probability')\n",
    "parser.add_argument('--dropout', type=float, default=0.0, help='regular dropout')\n",
    "parser.add_argument('--nz', type=int, default=32)\n",
    "parser.add_argument('--lrt', type=float, default=0.0001)\n",
    "parser.add_argument('--grad_clip', type=float, default=5.0)\n",
    "parser.add_argument('--epoch_size', type=int, default=2000)\n",
    "parser.add_argument('--warmstart', type=int, default=0, help='initialize with pretrained model')\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "parser.add_argument('--enable_tensorboard', action='store_true',\n",
    "                    help='Enables tensorboard logging.')\n",
    "parser.add_argument('--tensorboard_dir', type=str, default='models',\n",
    "                    help='path to the directory where to save tensorboard log. If passed empty path' \\\n",
    "                         ' no logs are saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d614316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_first = parser.parse_args([\"--model\", \"fwd-cnn-vae-fp\", \"--layers\", \"3\", \"--batch_size\", \"64\", \"--ncond\", \"20\", \"--npred\", \"20\", \"--lrt\", \"0.0001\", \"--nfeature\", \"256\", \"--dropout\", \"0.1\", \"--nz\", \"32\", \"--beta\", \"1e-06\", \"--z_dropout\", \"0.5\", \"--grad_clip\", \"5\", \"--warmstart\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6444ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading data shard: traffic-data/state-action-cost/data_i80_v0/trajectories-0400-0415/all_data.pth]\n",
      "Number of episodes: 1807\n",
      "[loading data splits: traffic-data/state-action-cost/data_i80_v0/splits.pth]\n",
      "[loading data stats: traffic-data/state-action-cost/data_i80_v0/data_stats.pth]\n",
      "[loading car sizes: traffic-data/state-action-cost/data_i80_v0/car_sizes.pth]\n",
      "[will save model as: models/model=fwd-cnn-vae-fp-layers=3-bsize=64-ncond=20-npred=20-lrt=0.0001-nfeature=256-dropout=0.1-nz=32-beta=1e-06-zdropout=0.5-gclip=5.0-warmstart=1-seed=1]\n"
     ]
    }
   ],
   "source": [
    "def main(opt):\n",
    "    random.seed(opt.seed)\n",
    "    numpy.random.seed(opt.seed)\n",
    "    torch.manual_seed(opt.seed)\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    dataloader = DataLoader(None, opt, opt.dataset)\n",
    "    \n",
    "    opt.model_file = f'{opt.model_dir}/model={opt.model}-layers={opt.layers}-bsize={opt.batch_size}-ncond={opt.ncond}-npred={opt.npred}-lrt={opt.lrt}-nfeature={opt.nfeature}-dropout={opt.dropout}'\n",
    "    if 'vae' in opt.model:\n",
    "        opt.model_file += f'-nz={opt.nz}'\n",
    "        opt.model_file += f'-beta={opt.beta}'\n",
    "        opt.model_file += f'-zdropout={opt.z_dropout}'\n",
    "\n",
    "    if opt.grad_clip != -1:\n",
    "        opt.model_file += f'-gclip={opt.grad_clip}'\n",
    "\n",
    "    opt.model_file += f'-warmstart={opt.warmstart}'\n",
    "    opt.model_file += f'-seed={opt.seed}'\n",
    "    print(f'[will save model as: {opt.model_file}]')\n",
    "    \n",
    "    opt.n_inputs = 4\n",
    "    opt.n_actions = 2\n",
    "    opt.height = 117\n",
    "    opt.width = 24\n",
    "    if opt.layers == 3:\n",
    "        opt.h_height = 14\n",
    "        opt.h_width = 3\n",
    "    elif opt.layers == 4:\n",
    "        opt.h_height = 7\n",
    "        opt.h_width = 1\n",
    "    opt.hidden_size = opt.nfeature * opt.h_height * opt.h_width\n",
    "\n",
    "    mfile = opt.model_file + '.step200000.model'\n",
    "    \n",
    "    return opt, mfile, dataloader\n",
    "\n",
    "opt, mfile, dataloader = main(opt_first)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ecdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading previous checkpoint: models/model=fwd-cnn-vae-fp-layers=3-bsize=64-ncond=20-npred=20-lrt=0.0001-nfeature=256-dropout=0.1-nz=32-beta=1e-06-zdropout=0.5-gclip=5.0-warmstart=1-seed=1.step200000.model]\n"
     ]
    }
   ],
   "source": [
    "def load_model(opt, mfile):\n",
    "    print(f'[loading previous checkpoint: {mfile}]')\n",
    "    torch.nn.Module.dump_patches = True\n",
    "    model = torch.load(mfile)\n",
    "    return model\n",
    "model = load_model(opt, mfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3dae9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     inputs, actions, targets, _, _ \u001b[38;5;241m=\u001b[39m dataloader\u001b[38;5;241m.\u001b[39mget_batch_fm(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, npred)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(inputs))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(dataloader, npred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(dataloader, npred\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mnpred):\n\u001b[0;32m----> 2\u001b[0m     inputs, actions, targets, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_fm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(inputs))\n",
      "File \u001b[0;32m~/Projects/pytorch-PPUU/dataloader.py:167\u001b[0m, in \u001b[0;36mDataLoader.get_batch_fm\u001b[0;34m(self, split, npred, cuda)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode_length \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m T:\n\u001b[1;32m    166\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, episode_length \u001b[38;5;241m-\u001b[39m T)\n\u001b[0;32m--> 167\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m     actions\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[s][t : t \u001b[38;5;241m+\u001b[39m T]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m    169\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates[s][t : t \u001b[38;5;241m+\u001b[39m T, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))  \u001b[38;5;66;03m# discard 6 neighbouring cars\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPUU/lib/python3.8/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "def predict(dataloader, npred=opt.npred):\n",
    "    inputs, actions, targets, _, _ = dataloader.get_batch_fm('train', npred)\n",
    "    print(type(inputs))\n",
    "predict(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677352c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
